### אלגוריתמים נפוצים ב- Machine Learning

ישנם מספר אלגוריתמים נפוצים שמשמשים בעולם ה- (Machine Learning). להלן סקירה של העיקריים שבהם:

---

#### **Neural Networks (רשתות נוירונים)**

רשתות נוירונים מדמות את אופן הפעולה של המוח האנושי, באמצעות מספר עצום של יחידות עיבוד (nodes) המקושרות זו לזו. האלגוריתם מצטיין בזיהוי תבניות מורכבות, ויש לו תפקיד מרכזי ביישומים כמו:

- תרגום שפות טבעיות (Natural Language Translation)
    
- זיהוי תמונות (Image Recognition)
    
- זיהוי דיבור (Speech Recognition)
    
- יצירת תמונות מלאכותיות (Image Generation)
    

---

#### **Linear Regression (רגרסיה ליניארית)**

אלגוריתם זה משמש לחיזוי ערכים מספריים, בהתבסס על קשר ליניארי בין משתנים שונים. לדוגמה, ניתן להשתמש בטכניקה כדי לחזות מחירי נדל"ן לפי נתוני עבר של מחירים באזור מסוים.

---

#### **Logistic Regression (רגרסיה לוגיסטית)**

מדובר באלגוריתם של (Supervised Learning), שמיועד לחיזוי משתנים קטגוריאליים - כלומר תוצאות בינאריות כמו "כן" או "לא". דוגמאות ליישום:

- סיווג הודעות ספאם
    
- בקרה על איכות בקו ייצור
    

---

#### **Clustering (אשכולות)**

במסגרת (Unsupervised Learning), אלגוריתמי clustering מזהים תבניות בנתונים ומאפשרים לקבץ פריטים הדומים זה לזה. המחשב מסייע לחוקרי נתונים לזהות הבדלים בין פריטים - כאלה שבני אדם אולי כלל לא היו מבחינים בהם.

---

#### **Decision Trees (עצים החלטיים)**

כפי שתואר קודם, Decision Trees משמשים לחיזוי ערכים מספריים (רגרסיה) וגם לסיווג קטגוריות. העץ מייצג רצף החלטות מקושרות שניתן לתאר באמצעות דיאגרמת עץ. אחד היתרונות המרכזיים: קל להבין, לבדוק ולבקר את האלגוריתם, בניגוד ל- (Neural Networks) שנחשבות ל"קופסה שחורה".

---

#### **Random Forests (יער רנדומלי)**

ב- Random Forest, התחזית מתקבלת מתוך שילוב של תוצאות שמתקבלות ממספר Decision Trees. כל עץ בודק תת- קבוצה שונה של הנתונים או התכונות, והמערכת משקללת את התוצאות לקבלת תחזית מדויקת ויציבה יותר. הטכניקה הזו מצמצמת את הסיכון להטיית יתר (overfitting) הקיימת בעץ החלטה בודד.



### **Support Vector Machines (SVM)**

אלגוריתם (Supervised Learning) שמיועד בעיקר לבעיות של סיווג (Classification), אך ניתן להתאים אותו גם לרגרסיה. הרעיון המרכזי הוא למצוא את ה"הפרדה" (Hyperplane) האופטימלית שמבדילה בצורה הטובה ביותר בין קבוצות נתונים שונות.

**יתרונות**:

- יעיל במיוחד בבעיות שבהן קיימת הבחנה ברורה בין קטגוריות.
    
- מסוגל לטפל בבעיות עם מימדיות גבוהה (High Dimensionality).
    

**חסרונות**:

- פחות מתאים לסטים גדולים מאוד של נתונים (עשוי להיות איטי).
    
- פחות פרשני - קשה להסביר איך בדיוק מתקבלת ההחלטה.
    

**שימושים נפוצים**:

- סיווג טקסט (כמו זיהוי ספאם)
    
- זיהוי תמונות
    
- ניתוח רגשות
    

---

### **K-Nearest Neighbors (KNN)**

אלגוריתם פשוט ואינטואיטיבי שבו התחזית עבור נקודת נתונים חדשה מבוססת על _"השכנים הקרובים ביותר"_ שלה במרחב. נמדד מרחק (לרוב באמצעות Euclidean distance) בין נקודות, והקטגוריה/הערך של הרוב קובעת את התוצאה.

**יתרונות**:

- קל ליישום ולהבנה.
    
- לא דורש תהליך למידה מפורש - אין "אימון" אלא חישוב לפי הנתונים הקיימים.
    

**חסרונות**:

- איטי מאוד בסטים גדולים (חישוב לכל דוגמה).
    
- רגיש מאוד לבחירת פרמטר K ולמימדים (curse of dimensionality).
    

**שימושים נפוצים**:

- סיווג מבוסס תוכן (Content-based filtering)
    
- ניתוח רפואי (למשל סיווג מחלות לפי תסמינים)
    

---

### **Gradient Boosting Machines (GBM) / XGBoost / LightGBM**

אלגוריתמים מתקדמים מבוססי Boosting - שיטה שבה כמה עצי החלטה חלשים (Weak Learners) מחוזקים שלב אחרי שלב כדי ליצור מודל חזק. כל עץ מתקן את הטעויות של קודמיו.

**יתרונות**:

- דיוק גבוה מאוד - נחשב לאחד האלגוריתמים המובילים בתחרויות (כמו Kaggle).
    
- מתאים גם לרגרסיה וגם לסיווג.
    

**חסרונות**:

- תהליך אימון מורכב, דורש כיוונון פרמטרים מדויק (Hyperparameter tuning).
    
- פחות פרשני - קשה להסביר למשתמשים מדוע הוחלט מה שהוחלט.
    

**שימושים נפוצים**:

- מערכות דירוג והמלצה (Recommendation Engines)
    
- ניתוח אשראי ובנקאות
    
- ניבוי נטישה של לקוחות
    

---

### איך בוחרים את האלגוריתם המתאים?


|**אלגוריתם**|**סוג למידה**|**שימושים עיקריים**|**יתרונות**|**חסרונות**|**דרישות מחשוב**|
|---|---|---|---|---|---|
|**Neural Networks**|Supervised / Unsupervised|תרגום שפה, זיהוי תמונה ודיבור, יצירת תמונות|יכולת לזהות תבניות מורכבות מאוד|"קופסה שחורה", קשה לפרשנות, דורש הרבה נתונים|גבוהה מאוד - GPU מומלץ|
|**Linear Regression**|Supervised|חיזוי ערכים כמותיים (כמו מחירי נדל"ן)|פשוט, קל לפרשנות|מניח קשר ליניארי בלבד|נמוכה|
|**Logistic Regression**|Supervised|סיווג בינארי (כן/לא), סינון ספאם|קל להבנה והטמעה|לא עובד טוב עם קשרים מורכבים|נמוכה|
|**Clustering**|Unsupervised|גילוי תבניות, ניתוח סגמנטים שיווקיים|מתאים לנתונים לא מתויגים|אין "תשובה נכונה" ברורה, קשה לאימות|בינונית|
|**Decision Trees**|Supervised|רגרסיה, סיווג, קבלת החלטות|פרשני, ניתן לאימות בקלות|נוטה להטיית יתר (Overfitting)|נמוכה עד בינונית|
|**Random Forests**|Supervised|חיזוי מדויק עם יציבות גבוהה|יציב, מצמצם הטיית יתר|איטי יותר, פחות פרשני|בינונית עד גבוהה|
|**SVM (Support Vector Machines)**|Supervised|סיווג טקסט, ניתוח רגשות, זיהוי תמונות|עובד טוב עם נתונים מורכבים וגבוליים|קשה להרחבה לנתונים גדולים, לא אינטואיטיבי|בינונית עד גבוהה|
|**KNN (K-Nearest Neighbors)**|Supervised|סיווג פשוט, ניתוח רפואי|אינטואיטיבי, לא דורש אימון|איטי בסטים גדולים, רגיש לרעש|עולה עם גודל הנתונים|
|**Gradient Boosting (GBM / XGBoost / LightGBM)**|Supervised|דירוגים, תחזיות עסקיות, סיכון אשראי|דיוק גבוה מאוד, מתמודד טוב עם מורכבויות|תהליך אימון איטי, דורש כיוונון פרמטרים|גבוהה מאוד|
### המלצות כלליות לפי צורך:

- **רוצה להבין מה קורה במודל?** → השתמש ב- Decision Trees או Logistic Regression.
    
- **צריך ביצועים גבוהים ותחזיות מדויקות?** → Gradient Boosting או Random Forest.
    
- **יש לך מעט נתונים?** → KNN או Logistic Regression.
    
- **עובד עם תמונות, קול או שפה טבעית?** → Neural Networks.
    
- **אין לך תוויות לנתונים?** → Clustering.
    
- **מערכת קריטית שדורשת דיוק ורציפות?** → שילוב של Random Forest ו- GBM.